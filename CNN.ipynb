{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luffy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/luffy/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, test accuracy: 0.0254042, loss: 20.8801\n",
      "step 100, test accuracy: 0.344111, loss: 2.77647\n",
      "step 200, test accuracy: 0.52194, loss: 1.80824\n",
      "step 300, test accuracy: 0.622402, loss: 1.41782\n",
      "step 400, test accuracy: 0.677829, loss: 1.19016\n",
      "step 500, test accuracy: 0.720554, loss: 1.0777\n",
      "step 600, test accuracy: 0.756351, loss: 0.938708\n",
      "step 700, test accuracy: 0.756351, loss: 0.887941\n",
      "step 800, test accuracy: 0.774827, loss: 0.841865\n",
      "step 900, test accuracy: 0.809469, loss: 0.754522\n",
      "step 1000, test accuracy: 0.823326, loss: 0.708289\n",
      "step 1100, test accuracy: 0.831409, loss: 0.677985\n",
      "step 1200, test accuracy: 0.838337, loss: 0.638494\n",
      "step 1300, test accuracy: 0.842956, loss: 0.624689\n",
      "step 1400, test accuracy: 0.844111, loss: 0.626332\n",
      "step 1500, test accuracy: 0.844111, loss: 0.612932\n",
      "step 1600, test accuracy: 0.854503, loss: 0.569524\n",
      "step 1700, test accuracy: 0.854503, loss: 0.565087\n",
      "step 1800, test accuracy: 0.867206, loss: 0.550617\n",
      "step 1900, test accuracy: 0.862587, loss: 0.549755\n",
      "step 2000, test accuracy: 0.876443, loss: 0.510148\n",
      "step 2100, test accuracy: 0.872979, loss: 0.499258\n",
      "step 2200, test accuracy: 0.881062, loss: 0.485307\n",
      "step 2300, test accuracy: 0.874134, loss: 0.514515\n",
      "step 2400, test accuracy: 0.878753, loss: 0.507032\n",
      "step 2500, test accuracy: 0.875289, loss: 0.492049\n",
      "step 2600, test accuracy: 0.886836, loss: 0.444225\n",
      "step 2700, test accuracy: 0.881062, loss: 0.447543\n",
      "step 2800, test accuracy: 0.886836, loss: 0.445326\n",
      "step 2900, test accuracy: 0.89261, loss: 0.435554\n",
      "step 3000, test accuracy: 0.891455, loss: 0.433298\n",
      "step 3100, test accuracy: 0.887991, loss: 0.450135\n",
      "step 3200, test accuracy: 0.891455, loss: 0.438998\n",
      "step 3300, test accuracy: 0.904157, loss: 0.405205\n",
      "step 3400, test accuracy: 0.8903, loss: 0.479928\n",
      "step 3500, test accuracy: 0.907621, loss: 0.401645\n",
      "step 3600, test accuracy: 0.901848, loss: 0.434153\n",
      "step 3700, test accuracy: 0.903002, loss: 0.421022\n",
      "step 3800, test accuracy: 0.904157, loss: 0.439091\n",
      "step 3900, test accuracy: 0.905312, loss: 0.428991\n",
      "step 4000, test accuracy: 0.911085, loss: 0.40763\n",
      "step 4100, test accuracy: 0.909931, loss: 0.419832\n",
      "step 4200, test accuracy: 0.91455, loss: 0.403698\n",
      "step 4300, test accuracy: 0.916859, loss: 0.377179\n",
      "step 4400, test accuracy: 0.91224, loss: 0.414692\n",
      "step 4500, test accuracy: 0.907621, loss: 0.425325\n",
      "step 4600, test accuracy: 0.921478, loss: 0.394585\n",
      "step 4700, test accuracy: 0.916859, loss: 0.396334\n",
      "step 4800, test accuracy: 0.915704, loss: 0.41014\n",
      "step 4900, test accuracy: 0.907621, loss: 0.426154\n",
      "step 5000, test accuracy: 0.921478, loss: 0.394869\n",
      "step 5100, test accuracy: 0.908776, loss: 0.42857\n",
      "step 5200, test accuracy: 0.918014, loss: 0.417845\n",
      "step 5300, test accuracy: 0.919169, loss: 0.400205\n",
      "step 5400, test accuracy: 0.918014, loss: 0.407162\n",
      "step 5500, test accuracy: 0.920323, loss: 0.402868\n",
      "step 5600, test accuracy: 0.909931, loss: 0.451346\n",
      "step 5700, test accuracy: 0.909931, loss: 0.459315\n",
      "step 5800, test accuracy: 0.915704, loss: 0.443558\n",
      "step 5900, test accuracy: 0.919169, loss: 0.416192\n",
      "step 6000, test accuracy: 0.918014, loss: 0.437447\n",
      "step 6100, test accuracy: 0.924942, loss: 0.410006\n",
      "step 6200, test accuracy: 0.919169, loss: 0.442774\n",
      "step 6300, test accuracy: 0.91224, loss: 0.471452\n",
      "step 6400, test accuracy: 0.919169, loss: 0.407574\n",
      "step 6500, test accuracy: 0.920323, loss: 0.417277\n",
      "step 6600, test accuracy: 0.918014, loss: 0.422551\n",
      "step 6700, test accuracy: 0.924942, loss: 0.400044\n",
      "step 6800, test accuracy: 0.919169, loss: 0.454586\n",
      "step 6900, test accuracy: 0.922633, loss: 0.404275\n",
      "step 7000, test accuracy: 0.924942, loss: 0.462554\n",
      "step 7100, test accuracy: 0.923788, loss: 0.429201\n",
      "step 7200, test accuracy: 0.919169, loss: 0.461661\n",
      "step 7300, test accuracy: 0.931871, loss: 0.395814\n",
      "step 7400, test accuracy: 0.923788, loss: 0.442353\n",
      "step 7500, test accuracy: 0.929561, loss: 0.395391\n",
      "step 7600, test accuracy: 0.913395, loss: 0.522306\n",
      "step 7700, test accuracy: 0.928406, loss: 0.415137\n",
      "step 7800, test accuracy: 0.921478, loss: 0.45981\n",
      "step 7900, test accuracy: 0.929561, loss: 0.439067\n",
      "step 8000, test accuracy: 0.931871, loss: 0.429213\n",
      "step 8100, test accuracy: 0.922633, loss: 0.447705\n",
      "step 8200, test accuracy: 0.913395, loss: 0.485711\n",
      "step 8300, test accuracy: 0.933025, loss: 0.42576\n",
      "step 8400, test accuracy: 0.920323, loss: 0.496535\n",
      "step 8500, test accuracy: 0.927252, loss: 0.458236\n",
      "step 8600, test accuracy: 0.926097, loss: 0.445187\n",
      "step 8700, test accuracy: 0.929561, loss: 0.416223\n",
      "step 8800, test accuracy: 0.93418, loss: 0.424454\n",
      "step 8900, test accuracy: 0.919169, loss: 0.504584\n",
      "step 9000, test accuracy: 0.922633, loss: 0.476162\n",
      "step 9100, test accuracy: 0.926097, loss: 0.449849\n",
      "step 9200, test accuracy: 0.929561, loss: 0.393292\n",
      "step 9300, test accuracy: 0.930716, loss: 0.43126\n",
      "step 9400, test accuracy: 0.93649, loss: 0.433651\n",
      "step 9500, test accuracy: 0.933025, loss: 0.413674\n",
      "step 9600, test accuracy: 0.929561, loss: 0.471349\n",
      "step 9700, test accuracy: 0.929561, loss: 0.487002\n",
      "step 9800, test accuracy: 0.926097, loss: 0.521799\n",
      "step 9900, test accuracy: 0.915704, loss: 0.567571\n",
      "best test accuracy: 0.93649\n",
      "final test accuracy 0.933025\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Fri Apr 27 20:51:42 2018\n",
    "\n",
    "@author: luffy\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "\n",
    "####################Load data############################\n",
    "\n",
    "#Data preprocessing\n",
    "\n",
    "def data_normalize(data_temp):\n",
    "    data_temp2=data_temp.T\n",
    "    data_temp2 -=np.mean(data_temp2,axis=0)\n",
    "    data_temp2 /=np.std(data_temp2,axis=0)\n",
    "    data_temp=data_temp2.T\n",
    "    return data_temp\n",
    "\n",
    "def Xload(paths):\n",
    "    data_list=[]\n",
    "    for path in paths:\n",
    "        temp=data_normalize(np.loadtxt(path))\n",
    "        data_list.append(temp)\n",
    "    ######合并acc_x/y/z,gyr_x/y/z\n",
    "    lenth=len(data_list[0])\n",
    "    width=len(data_list[0][1])\n",
    "    data_np=np.empty((lenth,width*6))\n",
    "    for i in range(width*6):\n",
    "        temp= i%6\n",
    "        data_np[:,i]=data_list[temp][:,i//6]\n",
    "    return data_np\n",
    "\n",
    "def Yload(path):\n",
    "    train_np= np.loadtxt(path)  \n",
    "    train_np1=list(train_np)\n",
    "    train_np2=list(map(int, train_np1))\n",
    "    ytrain_np=[train_value-1 for train_value in train_np2]\n",
    "    #Convert tags to onehot\n",
    "    batch_size = tf.size(ytrain_np)\n",
    "    labels = tf.expand_dims(ytrain_np, 1)\n",
    "    indices = tf.expand_dims(tf.range(0, batch_size, 1), 1)\n",
    "    concated = tf.concat([indices, labels],1)\n",
    "    onehot_labels = tf.sparse_to_dense(concated, tf.stack([batch_size, 21]), 1.0, 0.0)\n",
    "    return onehot_labels.eval()\n",
    "    \n",
    "input_types= [\"acc_x.txt\",\"acc_y.txt\",\"acc_z.txt\",\"gyr_x.txt\",\"gyr_y.txt\",\"gyr_z.txt\"]\n",
    "train_paths=[\"/Users/luffy/Desktop/gait_test/train/train_\"+ i for i in input_types]\n",
    "train_np=Xload(train_paths)\n",
    "test_paths=[\"/Users/luffy/Desktop/gait_test/test/test_\"+ i for i in input_types]\n",
    "test_np=Xload(test_paths)\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "ytrain_path= \"/Users/luffy/Desktop/gait_test/train/y_train.txt\"\n",
    "ytrain_label=Yload(ytrain_path)\n",
    "ytest_path= \"/Users/luffy/Desktop/gait_test/test/y_test.txt\"\n",
    "ytest_label=Yload(ytest_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################Set parameters###############################\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) # 变量的初始值为截断正太分布\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 128*6])  \n",
    "x_image = tf.reshape(x, [-1,16,8,6]) #reshape\n",
    "\n",
    "\"\"\"\n",
    "# first layer\n",
    "\"\"\"\n",
    "W_conv1 = weight_variable([5, 5, 6, 32])  \n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\"\"\"\n",
    "# second layer\n",
    "\"\"\"\n",
    "W_conv2 = weight_variable([5, 5, 32, 64]) \n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# third layer, the fully connected layer with an input dimension of 4*2*64 and an output dimension of 1024\n",
    "\"\"\"\n",
    "W_fc1 = weight_variable([4*2*64, 1024])  \n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 4*2*64]) \n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "keep_prob = tf.placeholder(tf.float32) \n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\"\"\"\n",
    "# fourth layer，with an input dimension of 1024 and an output dimension of 21，corresponding to 21 categories\n",
    "\"\"\"\n",
    "W_fc2 = weight_variable([1024, 21])\n",
    "b_fc2 = bias_variable([21])\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) #Use softmax as a multi-class activation function\n",
    "y_ = tf.placeholder(tf.float32, [None, 21])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1])) # Loss function，cross entropy\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) # Use Adam optimizer\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "log_dir='/Users/luffy/Desktop/gait_test/tensorboard/'  # Use tensorboard\n",
    "train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(log_dir+'test/')\n",
    "sess.run(tf.initialize_all_variables())  # Variable initialization\n",
    "optimal_accuracy = 0.0\n",
    "#train\n",
    "for i in range(10000):  \n",
    "    batch_x,batch_y = next_batch(50,train_np,ytrain_label)  \n",
    "    if i%100 == 0:\n",
    "        loss,test_accuracy,test_summary=sess.run([cross_entropy,accuracy,merged],feed_dict={\n",
    "            x:test_np, y_: ytest_label, keep_prob: 1.0})\n",
    "        test_writer.add_summary(test_summary, i)\n",
    "        print(\"step %d, test accuracy: %g, loss: %g\"%(i, test_accuracy,loss))\n",
    "        optimal_accuracy = max(optimal_accuracy, test_accuracy)\n",
    "    summary_, _ = sess.run([merged,train_optimizer],feed_dict={x: batch_x, y_: batch_y, keep_prob: 0.5})   \n",
    "    train_writer.add_summary(summary_, i)\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "\n",
    "print(\"best test accuracy: %g\"%(optimal_accuracy))\n",
    "print(\"final test accuracy %g\"%accuracy.eval(feed_dict={x: test_np, y_: ytest_label, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test accuracy 0.915704\n"
     ]
    }
   ],
   "source": [
    "print(\"final test accuracy %g\"%test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luffy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 1.6.0 at http://lixiangwus-MacBook-Air.local:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir='/Users/luffy/Desktop/gait_test/tensorboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://localhost:6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
